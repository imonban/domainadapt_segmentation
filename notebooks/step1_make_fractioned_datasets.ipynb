{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/media/Datacenter_storage/ramon_dataset_curations/kidney_segmentation/source/debias_seg/data/kits_stu_combined.pkl\",'rb') as f: \n",
    "   data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_data = [e for row in data for e in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import sha224\n",
    "def  make_hash(path,tag=None): \n",
    "    hash_val = sha224(path.encode('utf-8')).hexdigest()\n",
    "    out_name = f\"{hash_val}_{tag}.nii.gz\"\n",
    "    return out_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_root=\"/rodata/mi2c/banerjeei/m261066/kitsdata/\"\n",
    "with open('/media/Datacenter_storage/ramon_dataset_curations/kidney_segmentation/data/copy_items.txt','w')  as f: \n",
    "    for row in flat_data:\n",
    "        vol_path = row['image'] \n",
    "        lbl_path = row['label']\n",
    "        if 'kits'  in vol_path: \n",
    "            continue \n",
    "        vol_path = vol_path.replace(\"/media/Datacenter_storage/ramon_dataset_curations/kidney_segmentation/data/STU_noncon_dataset/\",\"./\")\n",
    "        lbl_path = lbl_path.replace(\"/media/Datacenter_storage/ramon_dataset_curations/kidney_segmentation/data/STU_noncon_dataset/\",\"./\")\n",
    "        #upload_vol = make_hash(vol_path,'vol') \n",
    "        #download_vol = make_hash(lbl_path,'lbl')\n",
    "        #print(f\"scp {vol_path} m261066@rohpc10.mayo.edu:{upload_root}{upload_vol}\",file=f)\n",
    "        #print(f\"scp {lbl_path} m261066@rohpc10.mayo.edu:{upload_root}{download_vol}\",file=f)\n",
    "        print(f\"{vol_path}\",file=f)\n",
    "        print(f\"{lbl_path}\",file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dsets=  list() \n",
    "for i,dset in enumerate(data): \n",
    "    new_dset = list() \n",
    "    for tup in dset: \n",
    "        new_tup  = tup.copy() \n",
    "        if tup['phase'] ==1: \n",
    "            new_tup['image'] = new_tup['image'].replace('/media/Datacenter_storage/ramon_dataset_curations/kidney_segmentation/source/kits_data_spec/kits21/data/','/rodata/mi2c/banerjeei/m261066/kitsdata/data')\n",
    "            new_tup['label'] = new_tup['label'].replace('/media/Datacenter_storage/ramon_dataset_curations/kidney_segmentation/source/kits_data_spec/kits21/data/','/rodata/mi2c/banerjeei/m261066/kitsdata/data')\n",
    "        else: \n",
    "            new_tup['image'] = new_tup['image'].replace('/media/Datacenter_storage/ramon_dataset_curations/kidney_segmentation/data/','/rodata/mi2c/banerjeei/m261066/')\n",
    "            new_tup['label'] = new_tup['label'].replace('/media/Datacenter_storage/ramon_dataset_curations/kidney_segmentation/data/','/rodata/mi2c/banerjeei/m261066/')\n",
    "            break \n",
    "        new_dset.append(new_tup)\n",
    "    new_dsets.append(new_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df  = pd.DataFrame(data[0])\n",
    "val = data[1] \n",
    "test = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_con = train_df[train_df['phase']==1].copy()\n",
    "train_non_con = train_df[train_df['phase']==0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_non_con= train_non_con.sample(frac=1,random_state=1996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open(\"/media/Datacenter_storage/ramon_dataset_curations/domainadapt_segmentation/configs/step0_baseline/train_baseline.json\",'r') as f: \n",
    "    template_json =  json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_non_con.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [int(np.floor(frac*train_non_con.shape[0]))+1  for frac in  np.arange(0.0,1.0,0.1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_non_con.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "for i,e in enumerate(np.arange(0.0,1,0.1)):\n",
    "    row_json = template_json.copy() \n",
    "    sub_noncon_df = train_non_con.iloc[0:ranges[i],:]\n",
    "    print(sub_noncon_df.shape)\n",
    "    #sub_noncon_df = train_non_con.sample(frac=e,random_state=1996)\n",
    "    tr_df = pd.concat([train_con,sub_noncon_df])\n",
    "    len(train_non_con)\n",
    "    tr_l = [row.to_dict() for n,row in tr_df.iterrows()]\n",
    "    new_pack = (tr_l,val,test) \n",
    "    sampling = int(e*10) \n",
    "    new_path = f\"/media/Datacenter_storage/ramon_dataset_curations/domainadapt_segmentation/data/data_{sampling}.pkl\" \n",
    "    new_config_path = f\"/media/Datacenter_storage/ramon_dataset_curations/domainadapt_segmentation/configs/step0_baseline/subsampling/data_{sampling}.json\"\n",
    "    row_json['log_dir'] = template_json['log_dir'].replace(\"baseline\",f\"sampling_{sampling}_p\") \n",
    "    row_json['log_dir'] = row_json['log_dir'].replace(\"step0\",\"step5\") \n",
    "    row_json['data_path'] =new_path \n",
    "    print(len(new_pack[0]))\n",
    "    with open(new_path,'wb') as f:\n",
    "        pkl.dump(new_pack,f)\n",
    "    with open(new_config_path,'w') as f: \n",
    "        json.dump(row_json,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('monai20')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc1523f8182b75152e539c6d1922475f8cc5afbfea85f670fb387f60019a1330"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
